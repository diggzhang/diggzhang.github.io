---
layout:     post
title:      "分析超大日志文件的梗"
subtitle:   "awk和sed才是代表文本分析的一切"
date:       2017-02-14
author:     "diggzhang"
header-img: "img/post-bg-unix-linux.jpg"
category:
tags:
     - awk/sed
---

## 需求背景

因为一次集中的数据清洗，我不得不处理几百G的文件，且由于没有好好斟酌打印日志的方法，最终得到一个4GB的庞然大物。

事后更恶心的是，在清洗过程中有一部分数据处理过程中出现了奇怪的问题，这个时候只能翻阅一下这个4GB成千上万行的日志。可是需要的信息不过几百行罢了，真是大海捞针。

## 折腾

精简问题就是，希望其实是定位文件的XX行到XX行，搜索一番上古神器`sed`足矣。

```shell
sed -n '124010628,124011648p' ./Huge.log
```

如上指定参数`-n`后面跟着`起始行,结束行p`就可以了。
